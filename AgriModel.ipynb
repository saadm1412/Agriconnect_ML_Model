{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ae8JfRFh8oFM"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dO9SgJbG8oFN"
      },
      "outputs": [],
      "source": [
        "# Step 2: Load the Dataset\n",
        "data = pd.read_csv('combined_data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1P0LU_48oFN",
        "outputId": "78c03a52-4cc9-4993-e2b1-15dbb761b3d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Preview:\n",
            "         id  district_id district_name  market_id  \\\n",
            "0  64888490            1    Ahmednagar        153   \n",
            "1  64888491            2         Akola        154   \n",
            "2  64888492            3     Amarawati       3111   \n",
            "3  64888493            7       Jalgaon        159   \n",
            "4  64888494           10        Mumbai       3108   \n",
            "\n",
            "                    market_name  commodity_id commodity_name variety  \\\n",
            "0                    Ahmednagar            24         Potato   Other   \n",
            "1                         Akola            24         Potato   Other   \n",
            "2  Amrawati(Frui & Veg. Market)            24         Potato   Local   \n",
            "3                       Jalgaon            24         Potato   Other   \n",
            "4              Vashi New Mumbai            24         Potato   Other   \n",
            "\n",
            "   min_price  max_price  modal_price        date  \n",
            "0        800       1800       1300.0  01-01-2024  \n",
            "1       1000       1400       1300.0  01-01-2024  \n",
            "2        500       1600       1050.0  01-01-2024  \n",
            "3        700       1500       1200.0  01-01-2024  \n",
            "4       1000       1600       1300.0  01-01-2024  \n",
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 149501 entries, 0 to 149500\n",
            "Data columns (total 12 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   id              149501 non-null  int64  \n",
            " 1   district_id     149501 non-null  int64  \n",
            " 2   district_name   149501 non-null  object \n",
            " 3   market_id       149501 non-null  int64  \n",
            " 4   market_name     149501 non-null  object \n",
            " 5   commodity_id    149501 non-null  int64  \n",
            " 6   commodity_name  149501 non-null  object \n",
            " 7   variety         149501 non-null  object \n",
            " 8   min_price       149501 non-null  int64  \n",
            " 9   max_price       149501 non-null  int64  \n",
            " 10  modal_price     149501 non-null  float64\n",
            " 11  date            149501 non-null  object \n",
            "dtypes: float64(1), int64(6), object(5)\n",
            "memory usage: 13.7+ MB\n"
          ]
        }
      ],
      "source": [
        "# Display the first few rows\n",
        "print(\"Dataset Preview:\")\n",
        "print(data.head())\n",
        "\n",
        "print(\"\\nDataset Information:\")\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaaaBPTa8oFN",
        "outputId": "51862419-c250-47e6-bff5-9b40613dd272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Missing Values in Each Column:\n",
            "id                0\n",
            "district_id       0\n",
            "district_name     0\n",
            "market_id         0\n",
            "market_name       0\n",
            "commodity_id      0\n",
            "commodity_name    0\n",
            "variety           0\n",
            "min_price         0\n",
            "max_price         0\n",
            "modal_price       0\n",
            "date              0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing Values in Each Column:\")\n",
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKLU_-yU8oFN",
        "outputId": "3b8f129e-7067-44a1-e854-57be87ad82a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Data Types After Conversion:\n",
            "id                         int64\n",
            "district_id                int64\n",
            "district_name             object\n",
            "market_id                  int64\n",
            "market_name               object\n",
            "commodity_id               int64\n",
            "commodity_name            object\n",
            "variety                   object\n",
            "min_price                  int64\n",
            "max_price                  int64\n",
            "modal_price              float64\n",
            "date              datetime64[ns]\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Convert Date Column to Datetime\n",
        "data['date'] = pd.to_datetime(data['date'], format='%d-%m-%Y', errors='coerce')\n",
        "\n",
        " #Step 5: Validate the Conversion\n",
        "print(\"\\nData Types After Conversion:\")\n",
        "print(data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlLmWN9O8oFO",
        "outputId": "0fd1df80-baf6-4d44-d85a-dd5001481980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary Statistics for Numerical Columns:\n",
            "                 id    district_id      market_id   commodity_id  \\\n",
            "count  1.495010e+05  149501.000000  149501.000000  149501.000000   \n",
            "mean   6.377761e+07      13.272874    1790.479181      66.685628   \n",
            "min    5.600188e+07       1.000000     153.000000      23.000000   \n",
            "25%    5.996066e+07      10.000000     177.000000      23.000000   \n",
            "50%    6.352752e+07      13.000000    1464.000000      24.000000   \n",
            "75%    6.745467e+07      15.000000    2494.000000      78.000000   \n",
            "max    7.237475e+07      36.000000   10121.000000     362.000000   \n",
            "std    4.541550e+06       7.634545    1539.240558      54.561742   \n",
            "\n",
            "           min_price      max_price    modal_price                        date  \n",
            "count  149501.000000  149501.000000  149501.000000                      149501  \n",
            "mean     1331.936469    2361.277336    1921.694020  2023-07-31 15:36:57.994528  \n",
            "min         1.000000       1.000000       1.000000         2022-01-01 00:00:00  \n",
            "25%       500.000000    1300.000000    1000.000000         2022-11-21 00:00:00  \n",
            "50%      1000.000000    1800.000000    1400.000000         2023-09-05 00:00:00  \n",
            "75%      1500.000000    2611.000000    2150.000000         2024-03-25 00:00:00  \n",
            "max     40000.000000  373787.000000   75000.000000         2024-12-13 00:00:00  \n",
            "std      1485.879283    2257.838151    1718.257153                         NaN  \n"
          ]
        }
      ],
      "source": [
        "# Step 6: Basic Summary Statistics\n",
        "print(\"\\nSummary Statistics for Numerical Columns:\")\n",
        "print(data.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzVq5UJh8oFO",
        "outputId": "aee5f7ff-b6e7-4199-b2aa-43f8e5599827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Feature Engineering Complete. Dataset Preview:\n",
            "         id  district_id  market_id  commodity_id  min_price  max_price  \\\n",
            "0  64888490            1        153            24        800       1800   \n",
            "1  64888491            2        154            24       1000       1400   \n",
            "2  64888492            3       3111            24        500       1600   \n",
            "3  64888493            7        159            24        700       1500   \n",
            "4  64888494           10       3108            24       1000       1600   \n",
            "\n",
            "   modal_price       date  month  year  ...  commodity_name_Tomato  \\\n",
            "0       1300.0 2024-01-01      1  2024  ...                  False   \n",
            "1       1300.0 2024-01-01      1  2024  ...                  False   \n",
            "2       1050.0 2024-01-01      1  2024  ...                  False   \n",
            "3       1200.0 2024-01-01      1  2024  ...                  False   \n",
            "4       1300.0 2024-01-01      1  2024  ...                  False   \n",
            "\n",
            "   variety_2nd Sort  variety_Green Gram Dal  variety_Hybrid  variety_Local  \\\n",
            "0             False                   False           False          False   \n",
            "1             False                   False           False          False   \n",
            "2             False                   False           False           True   \n",
            "3             False                   False           False          False   \n",
            "4             False                   False           False          False   \n",
            "\n",
            "   variety_Other  variety_Pole  variety_Red  variety_White  variety_White Fozi  \n",
            "0           True         False        False          False               False  \n",
            "1           True         False        False          False               False  \n",
            "2          False         False        False          False               False  \n",
            "3           True         False        False          False               False  \n",
            "4           True         False        False          False               False  \n",
            "\n",
            "[5 rows x 194 columns]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Extract Month and Year from Date\n",
        "data['month'] = data['date'].dt.month\n",
        "data['year'] = data['date'].dt.year\n",
        "\n",
        "# Step 2: Create a Price Range Feature\n",
        "data['price_range'] = data['max_price'] - data['min_price']\n",
        "\n",
        "# Step 3: One-Hot Encode Categorical Features\n",
        "# Encoding 'district_name', 'market_name', 'commodity_name', 'variety'\n",
        "encoded_data = pd.get_dummies(data, columns=['district_name', 'market_name', 'commodity_name', 'variety'], drop_first=True)\n",
        "\n",
        "# Step 4: Verify Feature Engineering\n",
        "print(\"\\nFeature Engineering Complete. Dataset Preview:\")\n",
        "print(encoded_data.head())\n",
        "\n",
        "# Optional: Save the Processed Dataset\n",
        "# encoded_data.to_csv('processed_combined_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUM_WoQf8oFO",
        "outputId": "06b8e33d-bb21-4f9f-a5a9-9b4ca518a782"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Set Size: (119600, 191)\n",
            "Testing Set Size: (29901, 191)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Define Features (X) and Target (y)\n",
        "# Drop unnecessary columns\n",
        "X = encoded_data.drop(columns=['id', 'modal_price', 'date'])  # Drop ID, modal_price (target), and date\n",
        "y = encoded_data['modal_price']\n",
        "\n",
        "# Step 2: Split the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Verify the Split\n",
        "print(f\"Training Set Size: {X_train.shape}\")\n",
        "print(f\"Testing Set Size: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NETBM6pUH9RM",
        "outputId": "e0d813ae-bab3-4a91-8afa-bfb68ea18363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: xgboost in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.26.1)\n",
            "Requirement already satisfied: scipy in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.13.1)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1aq6y8I8oFO",
        "outputId": "c91358ae-69ef-47cf-d227-0dca77fa5503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Performance:\n",
            "MAE: 58.53\n",
            "RMSE: 23211.50\n",
            "R²: 0.99\n",
            "\n",
            "Top Features by Importance:\n",
            "                         Feature  Importance\n",
            "4                      max_price    0.885968\n",
            "3                      min_price    0.096148\n",
            "7                    price_range    0.004667\n",
            "26          district_name_Nashik    0.002063\n",
            "1                      market_id    0.001730\n",
            "2                   commodity_id    0.001256\n",
            "5                          month    0.001044\n",
            "78             market_name_Karad    0.000761\n",
            "70  market_name_Junnar(Alephata)    0.000562\n",
            "6                           year    0.000536\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Step 1: Scale Features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 2: Train a Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=15, min_samples_split=10)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 3: Make Predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Step 4: Evaluate the Model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Performance:\\nMAE: {mae:.2f}\\nRMSE: {rmse:.2f}\\nR²: {r2:.2f}\")\n",
        "\n",
        "# Feature Importance\n",
        "importances = model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop Features by Importance:\")\n",
        "print(feature_importance_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7IzI5eQHyzM",
        "outputId": "8b70e166-ec8c-483c-b2b0-24beee466477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Model Performance:\n",
            "MAE: 49.05\n",
            "RMSE: 19125.10\n",
            "R²: 0.99\n",
            "\n",
            "Top Features by Importance (XGBoost):\n",
            "                                       Feature  Importance\n",
            "4                                    max_price    0.285684\n",
            "70                market_name_Junnar(Alephata)    0.242435\n",
            "176                  commodity_name_Green Peas    0.087485\n",
            "175  commodity_name_Green Gram Dal (Moong Dal)    0.035918\n",
            "3                                    min_price    0.032482\n",
            "26                        district_name_Nashik    0.021560\n",
            "61                           market_name_Ghoti    0.013802\n",
            "2                                 commodity_id    0.008939\n",
            "84                       market_name_Kopargaon    0.006893\n",
            "161                        market_name_Solapur    0.006574\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Step 1: Train an XGBoost Regressor\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=200,      # Number of trees\n",
        "    max_depth=15,          # Maximum depth of trees\n",
        "    learning_rate=0.1,     # Step size shrinkage\n",
        "    colsample_bytree=0.8,  # Subsample ratio of columns when constructing each tree\n",
        "    subsample=0.8,         # Subsample ratio of the training instance\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 2: Predict on the Test Set\n",
        "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
        "\n",
        "# Step 3: Evaluate XGBoost Model Performance\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "rmse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(f\"XGBoost Model Performance:\\nMAE: {mae_xgb:.2f}\\nRMSE: {rmse_xgb:.2f}\\nR²: {r2_xgb:.2f}\")\n",
        "\n",
        "# Compare Feature Importance (Optional)\n",
        "xgb_importance = xgb_model.feature_importances_\n",
        "xgb_feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': xgb_importance}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop Features by Importance (XGBoost):\")\n",
        "print(xgb_feature_importance_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM5J43y86pO0",
        "outputId": "ffe0ece1-5e36-4fea-fd15-e9af48768815"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['scaler.pkl']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'agri.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmzQAkgwOWSE",
        "outputId": "f0db6069-2ae9-47fe-d10e-7eb7c001dc2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Dataset Loaded Successfully!\n",
            "Testing Dataset Performance:\n",
            "MAE: 98.23\n",
            "RMSE: 65581.30\n",
            "R²: 0.98\n",
            "Predictions saved to 'Test_with_Predictions.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Step 1: Load the Testing Dataset\n",
        "test_data = pd.read_csv('Test.csv')\n",
        "print(\"Testing Dataset Loaded Successfully!\")\n",
        "\n",
        "# Step 2: Separate Features and Target (assuming 'modal_price' is the target column)\n",
        "X_test = test_data.drop(columns=['modal_price'], errors='ignore')  # Drop target column if it exists\n",
        "y_test = test_data['modal_price'] if 'modal_price' in test_data.columns else None  # Extract target if available\n",
        "\n",
        "# Step 3: One-Hot Encode Categorical Variables\n",
        "X_test_encoded = pd.get_dummies(X_test, columns=['district_name', 'market_name', 'commodity_name', 'variety'])\n",
        "\n",
        "# Step 4: Align with Training Data Columns\n",
        "missing_cols = set(X.columns) - set(X_test_encoded.columns)\n",
        "for col in missing_cols:\n",
        "    X_test_encoded[col] = 0\n",
        "X_test_encoded = X_test_encoded[X.columns]  # Reorder columns to match the training data\n",
        "\n",
        "# Step 5: Load the Trained Model and Scaler\n",
        "model = joblib.load('agri.pkl')\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "# Step 6: Scale the Testing Data\n",
        "X_test_scaled = scaler.transform(X_test_encoded)\n",
        "\n",
        "# Step 7: Predict on the Testing Data\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Step 8: Evaluate the Model (if Ground Truth Exists)\n",
        "if y_test is not None:\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"Testing Dataset Performance:\\nMAE: {mae:.2f}\\nRMSE: {rmse:.2f}\\nR²: {r2:.2f}\")\n",
        "else:\n",
        "    print(\"Ground truth (modal_price) not available in the testing dataset.\")\n",
        "\n",
        "# Step 9: Save Predictions\n",
        "test_data['Predicted_Modal_Price'] = y_pred\n",
        "test_data.to_csv('Test_with_Predictions.csv', index=False)\n",
        "print(\"Predictions saved to 'Test_with_Predictions.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVt901QF6xf8",
        "outputId": "c0e73f7f-edcd-46e9-88a2-83a25ae607a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The predicted price for Potato in Akola on 2025-01-26 is: 1874.23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\saadm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import joblib  # Assuming the model is saved as a .pkl file\n",
        "\n",
        "# Step 1: Load the trained model\n",
        "model_path = 'agri.pkl'  # Replace with your actual model file name\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "# Step 2: Prepare the input data\n",
        "def prepare_input(commodity_name, market_name, prediction_date):\n",
        "    # Create a DataFrame with placeholders for all features\n",
        "    input_data = pd.DataFrame(\n",
        "        columns=X.columns,  # X is the DataFrame used for training\n",
        "        data=[[0] * len(X.columns)]  # Initialize with zeros\n",
        "    )\n",
        "    # Set values for commodity_name, market_name, date features\n",
        "    input_data.loc[0, f\"commodity_name_{commodity_name}\"] = 1\n",
        "    input_data.loc[0, f\"market_name_{market_name}\"] = 1\n",
        "    # Assuming prediction_date is in 'YYYY-MM-DD' format\n",
        "    # input_data['date'] = prediction_date  # Include date if your model uses it\n",
        "    # ... (any other feature encoding logic) ...\n",
        "    return input_data\n",
        "\n",
        "# Step 3: Predict the price\n",
        "commodity_name = \"Potato\"\n",
        "market_name = \"Akola\"\n",
        "prediction_date = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')  # Tomorrow's date\n",
        "\n",
        "input_features = prepare_input(commodity_name, market_name, prediction_date)\n",
        "predicted_price = model.predict(input_features)\n",
        "\n",
        "# Display the result\n",
        "print(f\"The predicted price for {commodity_name} in {market_name} on {prediction_date} is: {predicted_price[0]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: supabase in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.11.0)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: gotrue<3.0.0,>=2.11.0 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from supabase) (2.11.1)\n",
            "Requirement already satisfied: httpx<0.29,>=0.26 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from supabase) (0.28.1)\n",
            "Requirement already satisfied: postgrest<0.20,>=0.19 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from supabase) (0.19.1)\n",
            "Requirement already satisfied: realtime<3.0.0,>=2.0.0 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from supabase) (2.1.0)\n",
            "Requirement already satisfied: storage3<0.12,>=0.10 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from supabase) (0.11.0)\n",
            "Requirement already satisfied: supafunc<0.10,>=0.9 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from supabase) (0.9.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.10 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.10.5)\n",
            "Requirement already satisfied: anyio in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (4.0.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (1.0.7)\n",
            "Requirement already satisfied: idna in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (3.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.14.0)\n",
            "Requirement already satisfied: deprecation<3.0.0,>=2.1.0 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from postgrest<0.20,>=0.19->supabase) (2.1.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.11 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from realtime<3.0.0,>=2.0.0->supabase) (3.11.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from realtime<3.0.0,>=2.0.0->supabase) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from realtime<3.0.0,>=2.0.0->supabase) (4.12.2)\n",
            "Requirement already satisfied: websockets<14,>=11 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from realtime<3.0.0,>=2.0.0->supabase) (13.1)\n",
            "Requirement already satisfied: strenum<0.5.0,>=0.4.15 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from supafunc<0.10,>=0.9->supabase) (0.4.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.11->realtime<3.0.0,>=2.0.0->supabase) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.11->realtime<3.0.0,>=2.0.0->supabase) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.11->realtime<3.0.0,>=2.0.0->supabase) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.11->realtime<3.0.0,>=2.0.0->supabase) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.11->realtime<3.0.0,>=2.0.0->supabase) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.11->realtime<3.0.0,>=2.0.0->supabase) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.11->realtime<3.0.0,>=2.0.0->supabase) (1.18.3)\n",
            "Requirement already satisfied: packaging in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from deprecation<3.0.0,>=2.1.0->postgrest<0.20,>=0.19->supabase) (23.1)\n",
            "Requirement already satisfied: h2<5,>=3 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (4.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil<3.0.0,>=2.8.1->realtime<3.0.0,>=2.0.0->supabase) (1.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from h2<5,>=3->httpx<0.29,>=0.26->supabase) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\saadm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from h2<5,>=3->httpx<0.29,>=0.26->supabase) (4.0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install supabase\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted: [{'market_name': 'Market1', 'commodity': 'Tomato', 'predicted_price': 160, 'prediction_date': '2025-01-26', 'id': 33}]\n",
            "Inserted: [{'market_name': 'Market1', 'commodity': 'Potato', 'predicted_price': 160, 'prediction_date': '2025-01-26', 'id': 34}]\n",
            "Inserted: [{'market_name': 'Market1', 'commodity': 'Onion', 'predicted_price': 150, 'prediction_date': '2025-01-26', 'id': 35}]\n",
            "Inserted: [{'market_name': 'Market1', 'commodity': 'Carrot', 'predicted_price': 160, 'prediction_date': '2025-01-26', 'id': 36}]\n",
            "Inserted: [{'market_name': 'Market1', 'commodity': 'Cabbage', 'predicted_price': 170, 'prediction_date': '2025-01-26', 'id': 37}]\n",
            "Inserted: [{'market_name': 'Market2', 'commodity': 'Tomato', 'predicted_price': 160, 'prediction_date': '2025-01-26', 'id': 38}]\n",
            "Inserted: [{'market_name': 'Market2', 'commodity': 'Potato', 'predicted_price': 160, 'prediction_date': '2025-01-26', 'id': 39}]\n",
            "Inserted: [{'market_name': 'Market2', 'commodity': 'Onion', 'predicted_price': 150, 'prediction_date': '2025-01-26', 'id': 40}]\n",
            "Inserted: [{'market_name': 'Market2', 'commodity': 'Carrot', 'predicted_price': 160, 'prediction_date': '2025-01-26', 'id': 41}]\n",
            "Inserted: [{'market_name': 'Market2', 'commodity': 'Cabbage', 'predicted_price': 170, 'prediction_date': '2025-01-26', 'id': 42}]\n",
            "Inserted: [{'market_name': 'Market3', 'commodity': 'Tomato', 'predicted_price': 160, 'prediction_date': '2025-01-26', 'id': 43}]\n",
            "Inserted: [{'market_name': 'Market3', 'commodity': 'Potato', 'predicted_price': 160, 'prediction_date': '2025-01-26', 'id': 44}]\n",
            "Inserted: [{'market_name': 'Market3', 'commodity': 'Onion', 'predicted_price': 150, 'prediction_date': '2025-01-26', 'id': 45}]\n",
            "Inserted: [{'market_name': 'Market3', 'commodity': 'Carrot', 'predicted_price': 160, 'prediction_date': '2025-01-26', 'id': 46}]\n",
            "Inserted: [{'market_name': 'Market3', 'commodity': 'Cabbage', 'predicted_price': 170, 'prediction_date': '2025-01-26', 'id': 47}]\n"
          ]
        }
      ],
      "source": [
        "from supabase import create_client, Client\n",
        "import pandas as pd\n",
        "\n",
        "# Supabase credentials\n",
        "SUPABASE_URL = \"https://xvvpvlblgkesguqbmblf.supabase.co\"\n",
        "SUPABASE_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Inh2dnB2bGJsZ2tlc2d1cWJtYmxmIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzU5NzI5MDQsImV4cCI6MjA1MTU0ODkwNH0.OexNIyW2DkHt3e_UZLYl3Xc9BToGsOFGKyU43hhYBXM\"\n",
        "\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize Supabase client\n",
        "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "\n",
        "# Function to insert predictions into Supabase\n",
        "def insert_predictions_to_supabase(predictions):\n",
        "    for prediction in predictions:\n",
        "        response = supabase.table(\"predicted_prices\").insert(prediction).execute()\n",
        "        print(f\"Inserted: {response.data}\")\n",
        "\n",
        "# Get tomorrow's date\n",
        "tomorrow_date = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "\n",
        "# Example dataset of commodities and markets (replace with your actual dataset)\n",
        "commodities = [\"Tomato\", \"Potato\", \"Onion\", \"Carrot\", \"Cabbage\"]  # List of commodities\n",
        "markets = [\"Market1\", \"Market2\", \"Market3\"]  # List of market names\n",
        "\n",
        "# Example prediction logic for all commodities in all markets\n",
        "predictions = []  # List to hold all predictions\n",
        "\n",
        "for market_name in markets:\n",
        "    for commodity in commodities:\n",
        "        # Replace this with your actual prediction logic\n",
        "        predicted_price = 100 + len(commodity) * 10  # Example predicted price\n",
        "\n",
        "        # Create a dictionary for the prediction\n",
        "        prediction = {\n",
        "            \"market_name\": market_name,\n",
        "            \"commodity\": commodity,\n",
        "            \"predicted_price\": predicted_price,\n",
        "            \"prediction_date\": tomorrow_date\n",
        "        }\n",
        "\n",
        "        # Add the prediction to the list\n",
        "        predictions.append(prediction)\n",
        "\n",
        "# Insert all predictions into Supabase\n",
        "insert_predictions_to_supabase(predictions)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
